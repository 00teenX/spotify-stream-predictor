{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be04600d-25e8-48a4-ac54-05efb5e5540e",
   "metadata": {},
   "source": [
    "# evaluation.ipynb\n",
    "\n",
    "**Projekt:** Spotify-Datensatz  \n",
    "**Autor:** Erjon Hulaj  \n",
    "**Datum:** 05.04.2025  \n",
    "\n",
    "## Evaluation des Modells\n",
    "In diesem Notebook analysiere ich die Qualität meines Vorhersagemodells anhand statistischer Metriken und einer Wahrheitsmatrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95986eb3-3afe-4edb-a28e-787e159e0754",
   "metadata": {},
   "source": [
    "## (4.1) Aussagekräftige Felder\n",
    "\n",
    "Für mein Modell zur Vorhersage der Popularität von Songs habe ich untersucht, welche Features besonders aussagekräftig sind.  \n",
    "Durch Korrelationen, visuelle Analyse (Scatterplots) und Modelltraining haben sich folgende Felder als besonders wichtig herausgestellt:\n",
    "\n",
    "- **energy**\n",
    "- **danceability**\n",
    "- **valence**\n",
    "- **loudness**\n",
    "- **duration_ms**\n",
    "\n",
    "Diese Felder haben eine erkennbare Verbindung zur Popularität, da sie musikalische Eigenschaften beschreiben, die den Hörgenuss und damit die Beliebtheit beeinflussen können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed42f5-544b-4813-ba36-a50bc8b8f723",
   "metadata": {},
   "source": [
    "## (4.2) Messmetrik: MSE und R²\n",
    "\n",
    "Ich habe den mittleren quadratischen Fehler (MSE) und das Bestimmtheitsmass (R²) verwendet, um mein Modell zu bewerten.  \n",
    "- **MSE** zeigt, wie stark die Vorhersagen vom tatsächlichen Wert abweichen (je kleiner, desto besser).\n",
    "- **R²** zeigt, wie viel der Zielvariable durch das Modell erklärt wird (max. 1.00).\n",
    "\n",
    "Diese Metriken sind bei Regressionsmodellen Standard und sehr gut geeignet zur Bewertung der Modellgüte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1d516c-8434-4a83-8155-e5bef8f932d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Datensatz laden\n",
    "df = pd.read_csv(\"/Users/erjon/Library/CloudStorage/OneDrive-AlteKantonsschuleAarau/BBB/Module/2. Jahr/M259/LB/dataset.csv\")\n",
    "\n",
    "# Features (X) und Zielvariable (y)\n",
    "X = df[[\"energy\", \"danceability\", \"loudness\", \"valence\", \"duration_ms\"]]\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "# Aufteilen in Training und Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74766fc2-2aa1-423a-abb6-436c91e14815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittlerer quadratischer Fehler (MSE): 488.86\n",
      "Bestimmtheitsmass (R²-Score): 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Metriken berechnen\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mittlerer quadratischer Fehler (MSE):\", round(mse, 2))\n",
    "print(\"Bestimmtheitsmass (R²-Score):\", round(r2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a44a66-3e87-43f9-9e85-82a5fea3f0df",
   "metadata": {},
   "source": [
    "### Bewertung der Modellqualität mit Metriken\n",
    "\n",
    "- **Mittlerer quadratischer Fehler (MSE)** liegt bei 488.86. Das bedeutet, dass die durchschnittliche quadratische Abweichung zwischen vorhergesagten und echten Popularitätswerten relativ hoch ist.\n",
    "- **Bestimmtheitsmass (R²-Score)** beträgt 0.01. Das Modell erklärt also nur ca. 1 % der Varianz in den Popularitätswerten. Dies zeigt, dass das lineare Modell die Zusammenhänge in den Daten nur sehr schlecht abbildet.\n",
    "\n",
    "→ Die Messmetriken bestätigen, dass das Modell noch deutliches Verbesserungspotenzial hat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d114eb-944b-488d-8493-87016f2e83bd",
   "metadata": {},
   "source": [
    "## (4.3) Wahrheitsmatrix, Recall & Precision\n",
    "\n",
    "Zur Bewertung meines Modells als Klassifikation habe ich die Popularität in zwei Klassen eingeteilt:  \n",
    "- Beliebt (>= 50)  \n",
    "- Nicht beliebt (< 50)\n",
    "\n",
    "Mit Hilfe einer Confusion Matrix konnte ich **Precision** (Genauigkeit) und **Recall** (Trefferquote) berechnen.  \n",
    "Diese zeigen, wie zuverlässig das Modell beliebte Songs erkennt. Dies ist besonders hilfreich, wenn man etwa gezielt nur erfolgreiche Songs empfehlen möchte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97436282-68f7-40a8-a810-6a54385d03a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrheitsmatrix (Confusion Matrix):\n",
      "[[17005     0]\n",
      " [ 5795     0]]\n",
      "\n",
      "Auswertung:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85     17005\n",
      "           1       0.00      0.00      0.00      5795\n",
      "\n",
      "    accuracy                           0.75     22800\n",
      "   macro avg       0.37      0.50      0.43     22800\n",
      "weighted avg       0.56      0.75      0.64     22800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Popularity binär einstufen: beliebt (>=50) = 1, sonst 0\n",
    "y_true_class = (y_test >= 50).astype(int)\n",
    "y_pred_class = (y_pred >= 50).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_class, y_pred_class)\n",
    "print(\"Wahrheitsmatrix (Confusion Matrix):\")\n",
    "print(cm)\n",
    "\n",
    "# Recall, Precision usw.\n",
    "print(\"\\nAuswertung:\")\n",
    "print(classification_report(y_true_class, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213d100-3b3a-415c-b32a-22050b1c15cb",
   "metadata": {},
   "source": [
    "#### Bewertung der Klassifikation\n",
    "\n",
    "Die Confusion Matrix zeigt, dass das Modell alle Songs als „nicht beliebt“ einstuft. Dadurch erkennt es keine tatsächlich beliebten Songs (Recall = 0.00), und es gibt auch keine echten positiven Vorhersagen (Precision = 0.00).\n",
    "\n",
    "Das Modell ist somit nicht fähig, beliebte Songs zuverlässig zu identifizieren. Es tendiert stark dazu, alles als „nicht beliebt“ zu bewerten. Sehr wahrscheinlich ist das so, weil die Popularitätswerte im Trainingssatz mehrheitlich unter der Schwelle von 50 liegen. Für diese Art der Klassifikation ist das Modell ungeeignet und müsste durch komplexere Methoden ersetzt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab9038-0205-4d9b-9bf8-dc7eea30d92b",
   "metadata": {},
   "source": [
    "### (4.4) Fazit zur Modellqualität\n",
    "\n",
    "Mein Modell kann grobe Trends in den Daten erkennen, liefert jedoch keine präzisen Vorhersagen.  \n",
    "Der **MSE** ist hoch und das **R²** liegt nahe bei 0.  \n",
    "Auch die Klassifikation zeigt, dass das Modell beliebte Songs nicht zuverlässig erkennt (**Recall** und **Precision** = 0 für Klasse 1).  \n",
    "\n",
    "→ **Hypothese:** Vermutlich reichen die gewählten Features nicht aus, um die Komplexität der Popularität vollständig abzubilden.  \n",
    "Mögliche Verbesserungen wären nicht-lineare Modelle (z. B. Entscheidungsbäume) oder weitere Features wie Genres, Interpreten oder Veröffentlichung."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (M259Env)",
   "language": "python",
   "name": "m259env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
